---
layout: about
title: about
permalink: /
subtitle:

profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
  address: ''

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
selected_repositories: true # includes links to repositories in 
social: true  # includes social icons at the bottom of the page
---

I'm interested in AI safety research. In short, this is because I believe competitive pressures will continue to push us towards a world filled with increasingly advanced AI systems operating and interacting in ways we -- as of now -- do not sufficiently understand.

Within AI safety, I'm particularly excited about projects focused on clarifying our understanding of the risks from advanced AI systems, such as developing [model organisms of misalignment](https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1), building [dangerous](https://www.gov.uk/government/publications/emerging-processes-for-frontier-ai-safety/emerging-processes-for-frontier-ai-safety#model-evaluations-and-red-teaming) [capabilities](https://evals.alignment.org) [evaluations](https://openai.com/blog/frontier-risk-and-preparedness), and [red teaming](https://www.anthropic.com/index/frontier-threats-red-teaming-for-ai-safety). While I intuitively believe advanced AI systems may pose serious risks, I find existing empirical evidence for such claims underwhelming. Safely experimenting with various threat models would shed light on the realism of these risks, allowing us to better prioritize research directions, develop products responsibly, and regulate appropriately.

I am also interested in the use of AI for promoting democracy. More specifically, I believe there is currently great potential for using LLMs to scale deliberative democracy and enable more representative, transparent, and thoughtful collective decision-making. Exciting projects on this front include [democratizing](https://openai.com/blog/democratic-inputs-to-ai-grant-program-update) the [governance of AI](https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input) as well as [automatically](https://compdemocracy.org) mapping [the opinion landscape](https://ai.objectives.institute/talk-to-the-city) on a given topic.

You can find links to my relevant pages in the icons above and below. I'm always happy to connect.
